{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8ea81b9",
   "metadata": {},
   "source": [
    "# ðŸ“ Steps for Working with `retail_store_inventory.csv`\n",
    "\n",
    "In this project, we need to explore, clean, and prepare the raw sales and inventory data before feeding it into forecasting and simulation models. Here are the detailed steps:\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Initial Data Exploration\n",
    "- Check dataset shape (rows Ã— columns).\n",
    "- Preview first few rows (`head`).\n",
    "- Inspect data types and missing values (`info`, `isnull().sum()`).\n",
    "- Generate summary statistics (`describe`).\n",
    "\n",
    "---\n",
    "wwdawdas\n",
    "\n",
    "\n",
    "   \n",
    "## 2. Identify Key Columns\n",
    "Expected columns are:\n",
    "- `date` â†’ date of the record  \n",
    "- `store_id` â†’ store/branch identifier  \n",
    "- `product_id` â†’ product identifier  \n",
    "- `sales_units` â†’ daily sales units  \n",
    "- `inventory_level` â†’ daily stock level  \n",
    "- `price` â†’ product price (if available)  \n",
    "- `promotion` or other contextual features (optional)\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Handle Missing Values\n",
    "- Detect missing values in each column.  \n",
    "- Decide how to fill:\n",
    "  - Replace with **0** if missing means no sales/stock.  \n",
    "  - Use **interpolation** if values are actually missing in sequence.  \n",
    "  - Drop rows if the missingness is negligible.  \n",
    "\n",
    "---\n",
    "\n",
    "## 4. Convert Data Types\n",
    "- Convert `date` â†’ **datetime**.  \n",
    "- Ensure numerical fields (`sales_units`, `inventory_level`, `price`) are numeric.  \n",
    "- Convert categorical fields (`store_id`, `product_id`) to **category** type.  \n",
    "\n",
    "---\n",
    "\n",
    "## 5. Check Uniqueness\n",
    "- How many unique products?  \n",
    "- How many unique stores?  \n",
    "- This helps narrow down the scope (e.g., focus on 2â€“3 products and 1â€“2 stores for the MVP).  \n",
    "\n",
    "---\n",
    "\n",
    "## 6. Time Series Analysis\n",
    "- Plot total daily sales to inspect overall trend.  \n",
    "- Plot per product/store to detect seasonality or weekly patterns.  \n",
    "- Look for trend, seasonality, and noise in the data.  \n",
    "\n",
    "---\n",
    "\n",
    "## 7. Distribution Analysis\n",
    "- Plot histogram of `sales_units` to check sales distribution.  \n",
    "- Plot histogram of `inventory_level` to assess stock variability.  \n",
    "- Identify potential outliers.  \n",
    "\n",
    "---\n",
    "\n",
    "## 8. Feature Relationships\n",
    "- Correlation between `price` and `sales_units` â†’ price elasticity.  \n",
    "- Effect of `promotion` on sales â†’ uplift estimation.  \n",
    "- If features are missing, create synthetic assumptions for simulation.  \n",
    "\n",
    "---\n",
    "\n",
    "## 9. Data Preparation for Modeling\n",
    "Restructure data into standard tables:\n",
    "- **sales.csv** â†’ [date, product_id, store_id, units, revenue]  \n",
    "- **inventory.csv** â†’ [date, product_id, store_id, stock_level]  \n",
    "- **products.csv** â†’ [product_id, name?, price, elasticity?, reorder_point, lead_time]  \n",
    "- **branches.csv** â†’ [store_id, city?]  \n",
    "\n",
    "---\n",
    "\n",
    "âœ… After these steps, the dataset will be clean and structured, ready for **Forecasting â†’ Simulation â†’ Agentic AI integration**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafed884",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eca3dd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import timesfm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from timesfm import ForecastConfig\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import  StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "190a737d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PY: c:\\Users\\Taha\\AppData\\Local\\Programs\\Python\\Python312\\python.exe\n",
      "timesfm from: C:\\Users\\Taha\\OneDrive\\Desktop\\OpenEdge-Project\\timesfm\\src\\timesfm\\__init__.py\n",
      "has TimesFm? False\n",
      "has old class? True\n"
     ]
    }
   ],
   "source": [
    "print(\"PY:\", sys.executable)\n",
    "print(\"timesfm from:\", timesfm.__file__)\n",
    "print(\"has TimesFm?\", hasattr(timesfm, \"TimesFm\"))\n",
    "print(\"has old class?\", hasattr(timesfm, \"TimesFM_2p5_200M_torch\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca5c84b",
   "metadata": {},
   "source": [
    "### 0) setting input and output paths :\n",
    "\n",
    "SRC means source path of the input file\n",
    "\n",
    "\n",
    "OUT_DIR means output directory where processed files will be saved\n",
    "\n",
    "  . path means a filesystem path\n",
    "\n",
    "  . out_dir.mkdir(parents=True, exist_ok=True) means create the output directory if it doesn't exist already\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "938249e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC  = r\"C:\\Users\\Taha\\OneDrive\\Desktop\\OpenEdge-Project\\retail_store_inventory.csv\"\n",
    "OUT_DIR = Path(\"./data/processed\")\n",
    "\n",
    "# parent=True allows creation of parent directories if they don't exist\n",
    "# exist_ok=True prevents error if the directory already exists\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True) # .mkdir is used to create directory if it doesn't exist\n",
    "OUT_STD = OUT_DIR / \"standardized_raw.csv\" \n",
    "\n",
    "df = pd.read_csv(SRC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32a0f84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "Store ID\n",
      "Product ID\n",
      "Category\n",
      "Region\n",
      "Inventory Level\n",
      "Units Sold\n",
      "Units Ordered\n",
      "Demand Forecast\n",
      "Price\n",
      "Discount\n",
      "Weather Condition\n",
      "Holiday/Promotion\n",
      "Competitor Pricing\n",
      "Seasonality\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ddc5dd",
   "metadata": {},
   "source": [
    "# 2) rename Ø¨Ù‡ snake_case \n",
    "    . snake_case means lowercase with underscores instead of spaces or camelCase\n",
    "    . rename columns to snake_case for consistency and easier access    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9323120",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_map = {\n",
    "    \"Date\": \"date\", #date means date of transaction\n",
    "    \"Store ID\": \"store_id\", #store_id means unique identifier for each store\n",
    "    \"Product ID\": \"product_id\", #product_id means unique identifier for each product\n",
    "    \"Category\": \"category\", #category means category of the product\n",
    "    \"Region\": \"region\", #region means geographical region of the store\n",
    "    \"Inventory Level\": \"inventory_level\", #inventory_level means current stock level of the product in the store\n",
    "    \"Units Sold\": \"units_sold\", #units_sold means number of units sold in the transaction\n",
    "                                #the total number of products sold by a company during a specific period\n",
    "    \"Units Ordered\": \"units_ordered\", #units_ordered means number of units ordered from suppliers\n",
    "    \"Demand Forecast\": \"demand_forecast\", #demand_forecast means predicted demand for the product\n",
    "    \"Price\": \"price\", \n",
    "    \"Discount\": \"discount\",\n",
    "    \"Weather Condition\": \"weather\",\n",
    "    \"Holiday/Promotion\": \"holiday_promo\", #holiday_promo means whether the transaction occurred during a holiday or promotion period\n",
    "    \"Supplier Lead Time\": \"supplier_lead_time\", #supplier_lead_time means time taken by supplier to deliver the product\n",
    "    \"Competitor Pricing\": \"competitor_price\", #competitor_price means price of similar products from competitors\n",
    "    \"Seasonality\": \"seasonality\", #seasonality means seasonal trend affecting the product sales\n",
    "}\n",
    "df = df.rename(columns=rename_map)\n",
    "\n",
    "# print(df[\"holiday_promo\"].value_counts()) # Check unique values in 'holiday_promo' column\n",
    "# print(df[\"weather\"].value_counts()) # Check unique values in 'weather' column\n",
    "# print(df[\"seasonality\"].value_counts()) # Check unique values in 'seasonality' column\n",
    "# print(df[\"category\"].value_counts()) # Check unique values in 'category' column\n",
    "# print(df[\"region\"].value_counts()) # Check unique values in 'region' column\n",
    "# print(df[\"date\"].min(), df[\"date\"].max()) # Check date range\n",
    "# print(df.isnull().sum()) # Check for missing values\n",
    "# print(df.dtypes) # Check data types of each column\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3168e83f",
   "metadata": {},
   "source": [
    "# 3) casting |>\n",
    "     .3.1 datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec32561e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"date\" in df.columns:\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\") # Convert to datetime, coerce errors to NaT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f410ea29",
   "metadata": {},
   "source": [
    "     .3.2 category/string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d45f7594",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in [\"store_id\", \"product_id\", \"category\", \"region\"]:\n",
    "    if c in df.columns:\n",
    "        df[c] = df[c].astype(\"string\")  # Convert to string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdc8043",
   "metadata": {},
   "source": [
    "     .3.2 numeric/stri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2a74f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in [\n",
    "    \"inventory_level\", \"units_sold\", \"units_ordered\", \"demand_forecast\",\n",
    "    \"price\", \"discount\", \"competitor_price\", \"seasonality\"\n",
    "]:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")  # Convert to numeric, coerce errors to NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "651428a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"holiday_promo\" in df.columns:\n",
    "    df[\"holiday_promo\"] = (\n",
    "        df[\"holiday_promo\"]\n",
    "        .astype(\"string\")\n",
    "        .str.lower()\n",
    "        .map({\n",
    "            \"yes\": 1, \"y\": 1, \"1\": 1,\n",
    "            \"no\": 0, \"n\": 0, \"0\": 0\n",
    "        })\n",
    "        .fillna(0)   # treat NaN as no\n",
    "        .astype(\"int8\")\n",
    "    )\n",
    "\n",
    "if \"weather\" in df.columns:\n",
    "    df[\"weather\"] = (\n",
    "        df[\"weather\"]\n",
    "        .astype(\"string\")\n",
    "        .str.lower()\n",
    "        .map({\n",
    "            \"sunny\": 0,\n",
    "            \"cloudy\": 1,\n",
    "            \"rainy\": 2,\n",
    "            \"snowy\": 3\n",
    "        })\n",
    "        .fillna(0)  # treat NaN as sunny\n",
    "        .astype(\"int8\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b796642d",
   "metadata": {},
   "source": [
    "# aggregation rules\n",
    "    .  sales_units = sum of sales_units per day per product per store\n",
    "    .  inventory_level = last recorded inventory_level per day per product per store\n",
    "    .  price = average price per day per product per store\n",
    "    .  discount = average discount per day per product per store\n",
    "    .  weather = most frequent weather condition per day per product per store\n",
    "    .  holiday_promo = most frequent holiday_promo status per day per product per store\n",
    "    .  seasonality = most frequent seasonality status per day per product per store\n",
    "    .  competitor_price = average competitor_price per day per product per store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "812c29ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key columns for grouping: ['date', 'store_id', 'product_id']\n",
      "\n",
      "Value columns for aggregation: ['inventory_level', 'price', 'discount', 'competitor_price', 'units_ordered', 'demand_forecast', 'holiday_promo', 'weather', 'category', 'region', 'seasonality']\n"
     ]
    }
   ],
   "source": [
    "agg_rules = {\n",
    "    \"unit_sold\": \"sum\", # total units sold in the day\n",
    "    \"inventory_level\": \"last\", # inventory level at the end of the day\n",
    "    'price': \"mean\", # average price of the product during the day\n",
    "    'discount': \"max\", # maximum discount offered during the day\n",
    "    \"competitor_price\": \"mean\", # average competitor price during the day\n",
    "    \"units_ordered\": \"sum\", # total units ordered from suppliers during the day\n",
    "    \"demand_forecast\": \"mean\", # means average predicted demand for the product\n",
    "    \"holiday_promo\": \"max\", # if any transaction during holiday/promo, mark as 1\n",
    "    \"weather\": \"last\", # worst weather condition during the day\n",
    "    \"category\": \"last\", # category of the product\n",
    "    \"region\": \"last\", # region of the store\n",
    "    \"seasonality\": \"last\" # seasonal trend affecting the product sales\n",
    "}\n",
    "\n",
    "# Determine key columns for grouping. It becauses dynamic to avoid KeyError if any column is missing.\n",
    "key_cols = [c for c in [\"date\", \"store_id\", \"product_id\"] if c in df.columns]\n",
    "print(\"Key columns for grouping:\", key_cols)\n",
    "print()\n",
    "value_cols = [c for c in agg_rules.keys() if c in df.columns and c not in key_cols]\n",
    "print(\"Value columns for aggregation:\", value_cols)\n",
    "\"\"\"\n",
    " --- Grouping and Aggregation ---\n",
    "1) Group the data by the key columns (date, store_id, product_id).\n",
    "    We use dropna=False so that rows with NaN in key columns are still included as separate groups.\n",
    "2) Select only the value columns we want to aggregate (e.g., units_sold, price, discount, etc.).\n",
    "3) Apply the aggregation rules defined in agg_rules:\n",
    "    - sum for total quantities (e.g., units_sold, units_ordered)\n",
    "    - mean for average values (e.g., price, competitor_price, demand_forecast)\n",
    "    - last for end-of-day or categorical values (e.g., inventory_level, weather, category, region)\n",
    "    - max for flags or discounts (e.g., discount, holiday_promo)\n",
    " 4) Reset the index so the grouped keys become normal columns again.\n",
    "\"\"\"\n",
    "if set(key_cols) == {\"date\",\"store_id\",\"product_id\"}: # Ensure all key columns are present\n",
    "    df = (\n",
    "        df.groupby(key_cols, dropna=False)[value_cols] # dropna=False to include NaN groups\n",
    "                                                       # groupby means to group data based on key columns\n",
    "          .agg({c: agg_rules[c] for c in value_cols}) # agg means to aggregate data based on agg_rules\n",
    "          .reset_index()\n",
    "    )\n",
    "else:\n",
    "    print(\"date, store_id, product_id\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03354b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Done standardization\n",
      "\n",
      "Shape: (73100, 14)\n",
      "\n",
      "Date range: 2022-01-01 00:00:00 â†’ 2024-01-01 00:00:00\n",
      "\n",
      "Null counts:\n",
      " date                    0\n",
      "store_id                0\n",
      "product_id              0\n",
      "inventory_level         0\n",
      "price                   0\n",
      "discount                0\n",
      "competitor_price        0\n",
      "units_ordered           0\n",
      "demand_forecast         0\n",
      "holiday_promo           0\n",
      "weather                 0\n",
      "category                0\n",
      "region                  0\n",
      "seasonality         73100\n",
      "dtype: int64\n",
      "\n",
      "Duplicates by (date, store_id, product_id): 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "store_id",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "product_id",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "inventory_level",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "price",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "discount",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "competitor_price",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "units_ordered",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "demand_forecast",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "holiday_promo",
         "rawType": "int8",
         "type": "integer"
        },
        {
         "name": "weather",
         "rawType": "int8",
         "type": "integer"
        },
        {
         "name": "category",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "region",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "seasonality",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "2a42537d-0c7b-4db8-9a9c-5aad9a9c4e43",
       "rows": [
        [
         "0",
         "2022-01-01 00:00:00",
         "S001",
         "P0001",
         "231",
         "33.5",
         "20",
         "29.69",
         "55",
         "135.47",
         "0",
         "2",
         "Groceries",
         "North",
         null
        ],
        [
         "1",
         "2022-01-01 00:00:00",
         "S001",
         "P0002",
         "204",
         "63.01",
         "20",
         "66.16",
         "66",
         "144.04",
         "0",
         "0",
         "Toys",
         "South",
         null
        ],
        [
         "2",
         "2022-01-01 00:00:00",
         "S001",
         "P0003",
         "102",
         "27.99",
         "10",
         "31.32",
         "51",
         "74.02",
         "1",
         "0",
         "Toys",
         "West",
         null
        ],
        [
         "3",
         "2022-01-01 00:00:00",
         "S001",
         "P0004",
         "469",
         "32.72",
         "10",
         "34.74",
         "164",
         "62.18",
         "1",
         "1",
         "Toys",
         "North",
         null
        ],
        [
         "4",
         "2022-01-01 00:00:00",
         "S001",
         "P0005",
         "166",
         "73.64",
         "0",
         "68.95",
         "135",
         "9.26",
         "0",
         "0",
         "Electronics",
         "East",
         null
        ],
        [
         "5",
         "2022-01-01 00:00:00",
         "S001",
         "P0006",
         "138",
         "76.83",
         "10",
         "79.35",
         "102",
         "139.82",
         "1",
         "0",
         "Groceries",
         "South",
         null
        ],
        [
         "6",
         "2022-01-01 00:00:00",
         "S001",
         "P0007",
         "359",
         "34.16",
         "10",
         "36.55",
         "167",
         "108.92",
         "1",
         "2",
         "Furniture",
         "East",
         null
        ],
        [
         "7",
         "2022-01-01 00:00:00",
         "S001",
         "P0008",
         "380",
         "97.99",
         "5",
         "100.09",
         "54",
         "329.73",
         "0",
         "1",
         "Clothing",
         "North",
         null
        ],
        [
         "8",
         "2022-01-01 00:00:00",
         "S001",
         "P0009",
         "183",
         "20.74",
         "10",
         "17.66",
         "135",
         "174.15",
         "0",
         "1",
         "Electronics",
         "West",
         null
        ],
        [
         "9",
         "2022-01-01 00:00:00",
         "S001",
         "P0010",
         "108",
         "59.99",
         "0",
         "61.21",
         "196",
         "24.47",
         "1",
         "2",
         "Toys",
         "South",
         null
        ]
       ],
       "shape": {
        "columns": 14,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>inventory_level</th>\n",
       "      <th>price</th>\n",
       "      <th>discount</th>\n",
       "      <th>competitor_price</th>\n",
       "      <th>units_ordered</th>\n",
       "      <th>demand_forecast</th>\n",
       "      <th>holiday_promo</th>\n",
       "      <th>weather</th>\n",
       "      <th>category</th>\n",
       "      <th>region</th>\n",
       "      <th>seasonality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>S001</td>\n",
       "      <td>P0001</td>\n",
       "      <td>231</td>\n",
       "      <td>33.50</td>\n",
       "      <td>20</td>\n",
       "      <td>29.69</td>\n",
       "      <td>55</td>\n",
       "      <td>135.47</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Groceries</td>\n",
       "      <td>North</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>S001</td>\n",
       "      <td>P0002</td>\n",
       "      <td>204</td>\n",
       "      <td>63.01</td>\n",
       "      <td>20</td>\n",
       "      <td>66.16</td>\n",
       "      <td>66</td>\n",
       "      <td>144.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Toys</td>\n",
       "      <td>South</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>S001</td>\n",
       "      <td>P0003</td>\n",
       "      <td>102</td>\n",
       "      <td>27.99</td>\n",
       "      <td>10</td>\n",
       "      <td>31.32</td>\n",
       "      <td>51</td>\n",
       "      <td>74.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Toys</td>\n",
       "      <td>West</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>S001</td>\n",
       "      <td>P0004</td>\n",
       "      <td>469</td>\n",
       "      <td>32.72</td>\n",
       "      <td>10</td>\n",
       "      <td>34.74</td>\n",
       "      <td>164</td>\n",
       "      <td>62.18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Toys</td>\n",
       "      <td>North</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>S001</td>\n",
       "      <td>P0005</td>\n",
       "      <td>166</td>\n",
       "      <td>73.64</td>\n",
       "      <td>0</td>\n",
       "      <td>68.95</td>\n",
       "      <td>135</td>\n",
       "      <td>9.26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>East</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>S001</td>\n",
       "      <td>P0006</td>\n",
       "      <td>138</td>\n",
       "      <td>76.83</td>\n",
       "      <td>10</td>\n",
       "      <td>79.35</td>\n",
       "      <td>102</td>\n",
       "      <td>139.82</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Groceries</td>\n",
       "      <td>South</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>S001</td>\n",
       "      <td>P0007</td>\n",
       "      <td>359</td>\n",
       "      <td>34.16</td>\n",
       "      <td>10</td>\n",
       "      <td>36.55</td>\n",
       "      <td>167</td>\n",
       "      <td>108.92</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>East</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>S001</td>\n",
       "      <td>P0008</td>\n",
       "      <td>380</td>\n",
       "      <td>97.99</td>\n",
       "      <td>5</td>\n",
       "      <td>100.09</td>\n",
       "      <td>54</td>\n",
       "      <td>329.73</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>North</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>S001</td>\n",
       "      <td>P0009</td>\n",
       "      <td>183</td>\n",
       "      <td>20.74</td>\n",
       "      <td>10</td>\n",
       "      <td>17.66</td>\n",
       "      <td>135</td>\n",
       "      <td>174.15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>West</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>S001</td>\n",
       "      <td>P0010</td>\n",
       "      <td>108</td>\n",
       "      <td>59.99</td>\n",
       "      <td>0</td>\n",
       "      <td>61.21</td>\n",
       "      <td>196</td>\n",
       "      <td>24.47</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Toys</td>\n",
       "      <td>South</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date store_id product_id  inventory_level  price  discount  \\\n",
       "0 2022-01-01     S001      P0001              231  33.50        20   \n",
       "1 2022-01-01     S001      P0002              204  63.01        20   \n",
       "2 2022-01-01     S001      P0003              102  27.99        10   \n",
       "3 2022-01-01     S001      P0004              469  32.72        10   \n",
       "4 2022-01-01     S001      P0005              166  73.64         0   \n",
       "5 2022-01-01     S001      P0006              138  76.83        10   \n",
       "6 2022-01-01     S001      P0007              359  34.16        10   \n",
       "7 2022-01-01     S001      P0008              380  97.99         5   \n",
       "8 2022-01-01     S001      P0009              183  20.74        10   \n",
       "9 2022-01-01     S001      P0010              108  59.99         0   \n",
       "\n",
       "   competitor_price  units_ordered  demand_forecast  holiday_promo  weather  \\\n",
       "0             29.69             55           135.47              0        2   \n",
       "1             66.16             66           144.04              0        0   \n",
       "2             31.32             51            74.02              1        0   \n",
       "3             34.74            164            62.18              1        1   \n",
       "4             68.95            135             9.26              0        0   \n",
       "5             79.35            102           139.82              1        0   \n",
       "6             36.55            167           108.92              1        2   \n",
       "7            100.09             54           329.73              0        1   \n",
       "8             17.66            135           174.15              0        1   \n",
       "9             61.21            196            24.47              1        2   \n",
       "\n",
       "      category region  seasonality  \n",
       "0    Groceries  North          NaN  \n",
       "1         Toys  South          NaN  \n",
       "2         Toys   West          NaN  \n",
       "3         Toys  North          NaN  \n",
       "4  Electronics   East          NaN  \n",
       "5    Groceries  South          NaN  \n",
       "6    Furniture   East          NaN  \n",
       "7     Clothing  North          NaN  \n",
       "8  Electronics   West          NaN  \n",
       "9         Toys  South          NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ’¾ Saved standardized file â†’ C:\\Users\\Taha\\OneDrive\\Desktop\\OpenEdge-Project\\data\\processed\\standardized_raw.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"âœ… Done standardization\\n\")\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"\\nDate range:\", df[\"date\"].min(), \"â†’\", df[\"date\"].max() if \"date\" in df.columns else \"(no date)\")\n",
    "print(\"\\nNull counts:\\n\", df.isnull().sum())\n",
    "\n",
    "# Check for duplicates based on key columns\n",
    "# all checks if all key columns are present in the dataframe\n",
    "# duplicated counts how many duplicate rows exist based on the subset of key columns\n",
    "# there are other methods except all like any, sum, etc.\n",
    "if all(k in df.columns for k in [\"date\",\"store_id\",\"product_id\"]): # Ensure all key columns are present\n",
    "    dups = df.duplicated(subset=[\"date\",\"store_id\",\"product_id\"]).sum() # Count duplicates based on key columns\n",
    "    print(\"\\nDuplicates by (date, store_id, product_id):\", dups)\n",
    "\n",
    "display(df.head(10))\n",
    "\n",
    "df.to_csv(OUT_STD, index=False)\n",
    "print(f\"\\nðŸ’¾ Saved standardized file â†’ {OUT_STD.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b3f382",
   "metadata": {},
   "source": [
    "#    Dataframe settings and secure copying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f162c3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfq = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c75cecae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows with units_sold_est > 0: 51466 | final units_sold nulls: 100\n"
     ]
    }
   ],
   "source": [
    "# Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ø§Øª Ø´ÛŒÙØª\n",
    "dfq = dfq.sort_values([\"store_id\",\"product_id\",\"date\"]).copy()\n",
    "\n",
    "# Ø§Ú¯Ø± Ø³ÙØ§Ø±Ø´ Ø¨Ø¹Ø¶ÛŒ Ø±ÙˆØ²Ù‡Ø§ NaN Ø§Ø³ØªØŒ Ø¨Ø±Ø§ÛŒ ØªØ®Ù…ÛŒÙ† ÙØ±ÙˆØ´ 0 Ø¯Ø± Ù†Ø¸Ø± Ø¨Ú¯ÛŒØ± (Ù…ÛŒâ€ŒØªÙˆÙ†ÛŒ Ø³ÛŒØ§Ø³Øª Ø¯ÛŒÚ¯Ø±ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒ)\n",
    "dfq[\"units_ordered\"] = pd.to_numeric(dfq[\"units_ordered\"], errors=\"coerce\").fillna(0)\n",
    "\n",
    "# Ù…ÙˆØ¬ÙˆØ¯ÛŒ Ø±ÙˆØ² Ù‚Ø¨Ù„ Ø¯Ø± Ù‡Ø± (store, product)\n",
    "dfq[\"prev_inventory\"] = dfq.groupby([\"store_id\",\"product_id\"])[\"inventory_level\"].shift(1)\n",
    "\n",
    "# ØªØ®Ù…ÛŒÙ† ÙØ±ÙˆØ´: prev + ordered - current ØŒ Ù…Ù†ÙÛŒâ€ŒÙ‡Ø§ Ø±Ø§ 0 Ú©Ù†\n",
    "dfq[\"units_sold_est\"] = (dfq[\"prev_inventory\"] + dfq[\"units_ordered\"] - dfq[\"inventory_level\"]).clip(lower=0)\n",
    "\n",
    "# Ø§Ú¯Ø± Ø³ØªÙˆÙ† units_sold ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯ØŒ Ù‡Ù…ÛŒÙ† ØªØ®Ù…ÛŒÙ† Ø±Ø§ Ø¨Ù‡â€ŒØ¹Ù†ÙˆØ§Ù† Ø³ØªÙˆÙ† ÙØ±ÙˆØ´ Ø§ØµÙ„ÛŒ Ø¨Ø³Ø§Ø²\n",
    "if \"units_sold\" not in dfq.columns:\n",
    "    dfq[\"units_sold\"] = dfq[\"units_sold_est\"]\n",
    "else:\n",
    "    # Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ØŒ ÙÙ‚Ø· Ø¬Ø§Ù‡Ø§ÛŒ Ø®Ø§Ù„ÛŒ Ø±Ø§ Ø¨Ø§ ØªØ®Ù…ÛŒÙ† Ù¾Ø± Ú©Ù†\n",
    "    dfq[\"units_sold\"] = pd.to_numeric(dfq[\"units_sold\"], errors=\"coerce\") # pd.to_numeric is used to convert a column to numeric type, coercing errors to NaN\n",
    "    dfq[\"units_sold\"] = dfq[\"units_sold\"].fillna(dfq[\"units_sold_est\"])\n",
    "\n",
    "# (Ø§Ø®ØªÛŒØ§Ø±ÛŒ) Ù¾Ø±Ú†Ù… Ø¨Ø¯Ù‡ Ú©Ù‡ Ú©Ø¬Ø§Ù‡Ø§ Ø§Ø² ØªØ®Ù…ÛŒÙ† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯\n",
    "dfq[\"units_sold_imputed_from_balance\"] = (\n",
    "    dfq[\"units_sold_est\"].notna() & ((\"units_sold\" not in dfq.columns) or dfq[\"units_sold\"].isna())\n",
    ").astype(\"int8\")\n",
    "\n",
    "print(\n",
    "    \"rows with units_sold_est > 0:\", int((dfq[\"units_sold_est\"]>0).sum()),\n",
    "    \"| final units_sold nulls:\", int(dfq[\"units_sold\"].isna().sum())\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdae76a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_cols = [c for c in [\"date\", \"store_id\", \"product_id\"] if c in df.columns]\n",
    "num_cols_missing_policy = [\"inventory_level\", \"price\", \"competitor_price\", \"units_ordered\", \"units_sold\"]\n",
    "num_cols_outlier_policy = [\"inventory_level\", \"price\", \"competitor_price\", \"units_ordered\", \"units_sold\"]\n",
    "\n",
    "# Missing Value Policy\n",
    "MISSING_DROP_THRESHOLD = 0.01  # If more than 50% values are missing, drop the column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea585cd",
   "metadata": {},
   "source": [
    "###     Flag Missing/Invalid and \"Delete if low, Impute if high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e364e0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing rates: {'inventory_level': '0.00%', 'price': '0.00%', 'competitor_price': '0.00%', 'units_ordered': '0.00%', 'units_sold': '0.14%'}\n",
      "Rows before dropping: 73100\n",
      "Dropped 100 rows due to low missing rates policy.\n"
     ]
    }
   ],
   "source": [
    "# Basic assertions to ensure key columns and date validity\n",
    "assert all(k in dfq.columns for k in key_cols), \"Key columns are missing in the dataframe\"\n",
    "assert dfq[\"date\"].notna().any(), \"No valid dates\"\n",
    "\n",
    "# Create missing value flags for numerical columns\n",
    "for col in num_cols_missing_policy:\n",
    "    if col in dfq.columns:\n",
    "        dfq[f\"{col}_isna\"] = dfq[col].isna().astype(\"int8\")  # Flag missing values\n",
    "\n",
    "# Calculate missing rates for numerical columns\n",
    "missing_rates = {} # Dictionary to store missing rates\n",
    "for col in num_cols_missing_policy:\n",
    "    if col in dfq.columns:\n",
    "        rate = dfq[f\"{col}_isna\"].mean() # Calculate missing rate\n",
    "        missing_rates[col] = rate # [col] is the key, rate is the value\n",
    "\n",
    "print(\"Missing rates:\", {k: f\"{v:.2%}\" for k, v in missing_rates.items()})\n",
    "\n",
    "# Decide which columns to drop or impute based on missing rates\n",
    "to_drop_mask = pd.Series(False, index=dfq.columns) # Initialize mask to False for all columns\n",
    "\n",
    "for col, rate in missing_rates.items():\n",
    "    if rate <= MISSING_DROP_THRESHOLD:\n",
    "        to_drop_mask = to_drop_mask | dfq[col].isna()\n",
    "    else:\n",
    "        dfq[f\"needs_impute_{col}\"] = dfq[col].isna().astype(\"int8\")\n",
    "\n",
    "# Drop rows with missing values in columns that are below the missing threshold\n",
    "rows_before = len(dfq)\n",
    "print(f\"Rows before dropping: {rows_before}\")\n",
    "\n",
    "# ~ means NOT, so we keep rows where to_drop_mask is False. ~ changes True to False and False to True\n",
    "# Reset index after dropping rows, drop=True avoids adding old index as a column\n",
    "dfq = dfq.loc[~to_drop_mask].reset_index(drop=True)\n",
    "rows_after = len(dfq)\n",
    "\n",
    "print(f\"Dropped {rows_before - rows_after} rows due to low missing rates policy.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be632b9e",
   "metadata": {},
   "source": [
    "### Winsorization with `groupby` + `apply`\n",
    "\n",
    "We use `groupby` on `[\"store_id\", \"product_id\"]` so that outlier detection is done **per storeâ€“product group** rather than across the whole dataset.  \n",
    "The helper function `_wins` is applied to each group separately.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example Data\n",
    "| store_id | product_id | price |\n",
    "|----------|------------|-------|\n",
    "| S1       | P1         | 100   |\n",
    "| S1       | P1         | 95    |\n",
    "| S1       | P2         | 50    |\n",
    "| S2       | P1         | 200   |\n",
    "| S2       | P1         | 210   |\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 1 â€” Grouping\n",
    "Groups created by `[\"store_id\",\"product_id\"]`:\n",
    "1. (S1,P1) â†’ [100, 95]  \n",
    "2. (S1,P2) â†’ [50]  \n",
    "3. (S2,P1) â†’ [200, 210]  \n",
    "\n",
    "---\n",
    "\n",
    "#### Step 2 â€” Winsorization per group\n",
    "- Compute **Q1, Q3, IQR** for the column (here: `price`) inside each group.  \n",
    "- Define bounds:  \n",
    "  - Lower Bound = Q1 âˆ’ 1.5 Ã— IQR  \n",
    "  - Upper Bound = Q3 + 1.5 Ã— IQR  \n",
    "- Clip values outside `[low, high]` back into the range.  \n",
    "- Mark rows that changed with an outlier flag.\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 3 â€” Output\n",
    "| store_id | product_id | price | price_outlier_flag | price_w | price_low_iqr | price_high_iqr |\n",
    "|----------|------------|-------|---------------------|---------|---------------|----------------|\n",
    "| S1       | P1         | 100   | 0                   | 100     | 87.5          | 107.5          |\n",
    "| S1       | P1         | 95    | 0                   | 95      | 87.5          | 107.5          |\n",
    "| S1       | P2         | 50    | 0                   | 50      | NaN           | NaN            |\n",
    "| S2       | P1         | 200   | 0                   | 200     | 185.0         | 225.0          |\n",
    "| S2       | P1         | 210   | 0                   | 210     | 185.0         | 225.0          |\n",
    "\n",
    "---\n",
    "\n",
    "#### Notes\n",
    "- `price_outlier_flag = 1` means the value was outside the IQR bounds and got clipped.  \n",
    "- `price_w` is the winsorized (clipped) version of `price`.  \n",
    "- `price_low_iqr` / `price_high_iqr` store the thresholds used for each group.  \n",
    "- In this example, no outliers were detected, so flags are 0 and clipped values equal original ones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "551312fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Taha\\AppData\\Local\\Temp\\ipykernel_15532\\2577900612.py:47: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_out = df_in.groupby(group_cols, group_keys=False).apply(_wins) # apply is used to apply a function along an axis of the DataFrame\n",
      "C:\\Users\\Taha\\AppData\\Local\\Temp\\ipykernel_15532\\2577900612.py:47: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_out = df_in.groupby(group_cols, group_keys=False).apply(_wins) # apply is used to apply a function along an axis of the DataFrame\n",
      "C:\\Users\\Taha\\AppData\\Local\\Temp\\ipykernel_15532\\2577900612.py:47: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_out = df_in.groupby(group_cols, group_keys=False).apply(_wins) # apply is used to apply a function along an axis of the DataFrame\n",
      "C:\\Users\\Taha\\AppData\\Local\\Temp\\ipykernel_15532\\2577900612.py:47: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_out = df_in.groupby(group_cols, group_keys=False).apply(_wins) # apply is used to apply a function along an axis of the DataFrame\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inventory_level: outliers flagged = 0\n",
      "price: outliers flagged = 0\n",
      "competitor_price: outliers flagged = 0\n",
      "units_ordered: outliers flagged = 0\n",
      "units_sold: outliers flagged = 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Taha\\AppData\\Local\\Temp\\ipykernel_15532\\2577900612.py:47: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_out = df_in.groupby(group_cols, group_keys=False).apply(_wins) # apply is used to apply a function along an axis of the DataFrame\n"
     ]
    }
   ],
   "source": [
    "group_cols = [\"store_id\", \"product_id\"]\n",
    "\n",
    "def winsorize_grouped(df_in, col, group_cols, k=1.5):\n",
    "    \"\"\"\n",
    "    Winsorize a numerical column within each group to limit the effect of outliers.\n",
    "    \n",
    "    Parameters:\n",
    "    - group: DataFrameGroupBy object\n",
    "    - col: Column name to winsorize\n",
    "    - lower_quantile: Lower quantile threshold (default 1%)\n",
    "    - upper_quantile: Upper quantile threshold (default 99%)\n",
    "    \n",
    "    Returns:\n",
    "    - Series with winsorized values\n",
    "\n",
    "    1) Calculate Q1 (25th percentile) and Q3 (75th percentile) for the specified column within each group.\n",
    "    2) Compute the IQR (Interquartile Range) as Q3 - Q1.\n",
    "    3) Determine the lower and upper bounds for outliers using the formula:\n",
    "         - Lower Bound = Q1 - k * IQR\n",
    "         - Upper Bound = Q3 + k * IQR\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    .Creates a function that operates on a numeric column (col).\n",
    "    .Copies the data (so the original is not corrupted).\n",
    "    .Adds a flag column (e.g. price_outlier_flag) that starts with zero.\n",
    "    \"\"\"\n",
    "    df_in = df_in.copy()\n",
    "    flag_col = f\"{col}_outlier_flag\"\n",
    "    df_in[flag_col] = 0  # Initialize outlier flag column\n",
    "    \n",
    "    def _wins(group):\n",
    "     x = group[col]\n",
    "     q1 = x.quantile(0.25)\n",
    "     q3 = x.quantile(0.75)\n",
    "     iqr = q3 - q1\n",
    "     low = q1 - k * iqr\n",
    "     high = q3 + k * iqr\n",
    "     clipped = x.clip(lower=low, upper=high)\n",
    "     changed = (clipped != x) & x.notna() # Only flag non-NaN changes. For example, if original is NaN and clipped is NaN, no change.\n",
    "     \n",
    "     group[flag_col] = changed.astype(\"int8\")\n",
    "     group[f\"{col}_w\"] = clipped\n",
    "     group[f\"{col}_low_iqr\"] = low\n",
    "     group[f\"{col}_high_iqr\"] = high\n",
    "     return group\n",
    "    \n",
    "    df_out = df_in.groupby(group_cols, group_keys=False).apply(_wins) # apply is used to apply a function along an axis of the DataFrame\n",
    "    return df_out\n",
    "\n",
    "for col in num_cols_outlier_policy:\n",
    "    if col in dfq.columns:\n",
    "        dfq = winsorize_grouped(dfq, col, group_cols)\n",
    "\n",
    "for col in num_cols_outlier_policy:\n",
    "    if f\"{col}_outlier_flag\" in dfq.columns:\n",
    "        print(f\"{col}: outliers flagged =\", int(dfq[f\"{col}_outlier_flag\"].sum()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afde2199",
   "metadata": {},
   "source": [
    "###    Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca17e0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Imputation done. Columns with *_imputed added:\n",
      "['units_sold_imputed', 'inventory_level_imputed', 'price_imputed', 'competitor_price_imputed']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Taha\\AppData\\Local\\Temp\\ipykernel_15532\\2013499725.py:47: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: impute_units_sold(g, col))\n",
      "C:\\Users\\Taha\\AppData\\Local\\Temp\\ipykernel_15532\\2013499725.py:26: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  x = x.fillna(method=\"ffill\", limit=2)\n",
      "C:\\Users\\Taha\\AppData\\Local\\Temp\\ipykernel_15532\\2013499725.py:52: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: impute_inventory(g, col))\n",
      "C:\\Users\\Taha\\AppData\\Local\\Temp\\ipykernel_15532\\2013499725.py:33: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  x = x.fillna(method=\"ffill\", limit=3)\n",
      "C:\\Users\\Taha\\AppData\\Local\\Temp\\ipykernel_15532\\2013499725.py:57: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: impute_price(g, col))\n",
      "C:\\Users\\Taha\\AppData\\Local\\Temp\\ipykernel_15532\\2013499725.py:33: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  x = x.fillna(method=\"ffill\", limit=3)\n",
      "C:\\Users\\Taha\\AppData\\Local\\Temp\\ipykernel_15532\\2013499725.py:57: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: impute_price(g, col))\n"
     ]
    }
   ],
   "source": [
    "# === 7) Imputation for missing values ===\n",
    "# We'll handle numeric columns separately with simple, transparent rules.\n",
    "\n",
    "impute_rules = {\n",
    "    \"units_sold\": \"rolling_mean\",        # 7-day rolling mean for long gaps\n",
    "    \"inventory_level\": \"ffill_then_med\", # forward-fill short gaps, median for long gaps\n",
    "    \"price\": \"ffill_then_mean\",          # forward-fill short gaps, mean for long gaps\n",
    "    \"competitor_price\": \"ffill_then_mean\"\n",
    "}\n",
    "\n",
    "# Make a copy to avoid messing dfq\n",
    "df_imp = dfq.copy()\n",
    "\n",
    "# Helper functions\n",
    "def impute_units_sold(group, col=\"units_sold\", window=7):\n",
    "    x = group[col]\n",
    "    # short gaps interpolate\n",
    "    x = x.interpolate(limit=3, limit_direction=\"both\")\n",
    "    # remaining gaps: rolling mean\n",
    "    if x.isna().any():\n",
    "        x = x.fillna(x.rolling(window, min_periods=1).mean())\n",
    "    return x\n",
    "\n",
    "def impute_inventory(group, col=\"inventory_level\", window=7):\n",
    "    x = group[col]\n",
    "    x = x.fillna(method=\"ffill\", limit=2)\n",
    "    if x.isna().any():\n",
    "        x = x.fillna(x.rolling(window, min_periods=1).median())\n",
    "    return x\n",
    "\n",
    "def impute_price(group, col, window=7):\n",
    "    x = group[col]\n",
    "    x = x.fillna(method=\"ffill\", limit=3)\n",
    "    if x.isna().any():\n",
    "        x = x.fillna(x.rolling(window, min_periods=1).mean())\n",
    "    return x\n",
    "\n",
    "# Apply imputation per (store_id, product_id)\n",
    "group_cols = [\"store_id\",\"product_id\"]\n",
    "\n",
    "for col, rule in impute_rules.items():\n",
    "    if col not in df_imp.columns:\n",
    "        continue\n",
    "    if rule == \"rolling_mean\":\n",
    "        df_imp[col+\"_imputed\"] = (\n",
    "            df_imp.groupby(group_cols, group_keys=False)\n",
    "                  .apply(lambda g: impute_units_sold(g, col))\n",
    "        )\n",
    "    elif rule == \"ffill_then_med\":\n",
    "        df_imp[col+\"_imputed\"] = (\n",
    "            df_imp.groupby(group_cols, group_keys=False)\n",
    "                  .apply(lambda g: impute_inventory(g, col))\n",
    "        )\n",
    "    elif rule == \"ffill_then_mean\":\n",
    "        df_imp[col+\"_imputed\"] = (\n",
    "            df_imp.groupby(group_cols, group_keys=False)\n",
    "                  .apply(lambda g: impute_price(g, col))\n",
    "        )\n",
    "\n",
    "print(\"âœ… Imputation done. Columns with *_imputed added:\")\n",
    "print([c for c in df_imp.columns if c.endswith(\"_imputed\")])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f688f23",
   "metadata": {},
   "source": [
    "# Cell 1 â€” pick dataframe + pick target + sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ec86934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dataframe: df_imp\n",
      "TARGET_COL = inventory_level_imputed\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "store_id",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "product_id",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "inventory_level",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "price",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "discount",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "competitor_price",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "units_ordered",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "demand_forecast",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "holiday_promo",
         "rawType": "int8",
         "type": "integer"
        },
        {
         "name": "weather",
         "rawType": "int8",
         "type": "integer"
        },
        {
         "name": "category",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "region",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "seasonality",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "prev_inventory",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "units_sold_est",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "units_sold",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "units_sold_imputed_from_balance",
         "rawType": "int8",
         "type": "integer"
        },
        {
         "name": "inventory_level_isna",
         "rawType": "int8",
         "type": "integer"
        },
        {
         "name": "price_isna",
         "rawType": "int8",
         "type": "integer"
        },
        {
         "name": "competitor_price_isna",
         "rawType": "int8",
         "type": "integer"
        },
        {
         "name": "units_ordered_isna",
         "rawType": "int8",
         "type": "integer"
        },
        {
         "name": "units_sold_isna",
         "rawType": "int8",
         "type": "integer"
        },
        {
         "name": "inventory_level_outlier_flag",
         "rawType": "int8",
         "type": "integer"
        },
        {
         "name": "inventory_level_w",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "inventory_level_low_iqr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "inventory_level_high_iqr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "price_outlier_flag",
         "rawType": "int8",
         "type": "integer"
        },
        {
         "name": "price_w",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "price_low_iqr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "price_high_iqr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "competitor_price_outlier_flag",
         "rawType": "int8",
         "type": "integer"
        },
        {
         "name": "competitor_price_w",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "competitor_price_low_iqr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "competitor_price_high_iqr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "units_ordered_outlier_flag",
         "rawType": "int8",
         "type": "integer"
        },
        {
         "name": "units_ordered_w",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "units_ordered_low_iqr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "units_ordered_high_iqr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "units_sold_outlier_flag",
         "rawType": "int8",
         "type": "integer"
        },
        {
         "name": "units_sold_w",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "units_sold_low_iqr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "units_sold_high_iqr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "units_sold_imputed",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "inventory_level_imputed",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "price_imputed",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "competitor_price_imputed",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "65230369-a25f-457d-8f51-dd459df21d9c",
       "rows": [
        [
         "0",
         "2022-01-02 00:00:00",
         "S001",
         "P0001",
         "116",
         "27.95",
         "10",
         "30.89",
         "104",
         "92.94",
         "0",
         "1",
         "Groceries",
         "West",
         null,
         "231.0",
         "219.0",
         "219.0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "116",
         "-182.625",
         "730.375",
         "0",
         "27.95",
         "-31.241249999999972",
         "142.40874999999997",
         "0",
         "30.89",
         "-33.01374999999998",
         "143.37624999999997",
         "0",
         "104",
         "-67.0",
         "285.0",
         "0",
         "219.0",
         "-359.625",
         "599.375",
         "219.0",
         "116",
         "27.95",
         "30.89"
        ],
        [
         "1",
         "2022-01-03 00:00:00",
         "S001",
         "P0001",
         "154",
         "62.7",
         "20",
         "58.22",
         "189",
         "5.36",
         "0",
         "2",
         "Electronics",
         "West",
         null,
         "116.0",
         "151.0",
         "151.0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "154",
         "-182.625",
         "730.375",
         "0",
         "62.7",
         "-31.241249999999972",
         "142.40874999999997",
         "0",
         "58.22",
         "-33.01374999999998",
         "143.37624999999997",
         "0",
         "189",
         "-67.0",
         "285.0",
         "0",
         "151.0",
         "-359.625",
         "599.375",
         "151.0",
         "154",
         "62.7",
         "58.22"
        ],
        [
         "2",
         "2022-01-04 00:00:00",
         "S001",
         "P0001",
         "85",
         "77.88",
         "15",
         "75.99",
         "193",
         "52.87",
         "1",
         "1",
         "Groceries",
         "South",
         null,
         "154.0",
         "262.0",
         "262.0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "85",
         "-182.625",
         "730.375",
         "0",
         "77.88",
         "-31.241249999999972",
         "142.40874999999997",
         "0",
         "75.99",
         "-33.01374999999998",
         "143.37624999999997",
         "0",
         "193",
         "-67.0",
         "285.0",
         "0",
         "262.0",
         "-359.625",
         "599.375",
         "262.0",
         "85",
         "77.88",
         "75.99"
        ]
       ],
       "shape": {
        "columns": 47,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>inventory_level</th>\n",
       "      <th>price</th>\n",
       "      <th>discount</th>\n",
       "      <th>competitor_price</th>\n",
       "      <th>units_ordered</th>\n",
       "      <th>demand_forecast</th>\n",
       "      <th>holiday_promo</th>\n",
       "      <th>...</th>\n",
       "      <th>units_ordered_low_iqr</th>\n",
       "      <th>units_ordered_high_iqr</th>\n",
       "      <th>units_sold_outlier_flag</th>\n",
       "      <th>units_sold_w</th>\n",
       "      <th>units_sold_low_iqr</th>\n",
       "      <th>units_sold_high_iqr</th>\n",
       "      <th>units_sold_imputed</th>\n",
       "      <th>inventory_level_imputed</th>\n",
       "      <th>price_imputed</th>\n",
       "      <th>competitor_price_imputed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>S001</td>\n",
       "      <td>P0001</td>\n",
       "      <td>116</td>\n",
       "      <td>27.95</td>\n",
       "      <td>10</td>\n",
       "      <td>30.89</td>\n",
       "      <td>104</td>\n",
       "      <td>92.94</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-67.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>-359.625</td>\n",
       "      <td>599.375</td>\n",
       "      <td>219.0</td>\n",
       "      <td>116</td>\n",
       "      <td>27.95</td>\n",
       "      <td>30.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>S001</td>\n",
       "      <td>P0001</td>\n",
       "      <td>154</td>\n",
       "      <td>62.70</td>\n",
       "      <td>20</td>\n",
       "      <td>58.22</td>\n",
       "      <td>189</td>\n",
       "      <td>5.36</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-67.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>-359.625</td>\n",
       "      <td>599.375</td>\n",
       "      <td>151.0</td>\n",
       "      <td>154</td>\n",
       "      <td>62.70</td>\n",
       "      <td>58.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>S001</td>\n",
       "      <td>P0001</td>\n",
       "      <td>85</td>\n",
       "      <td>77.88</td>\n",
       "      <td>15</td>\n",
       "      <td>75.99</td>\n",
       "      <td>193</td>\n",
       "      <td>52.87</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-67.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>-359.625</td>\n",
       "      <td>599.375</td>\n",
       "      <td>262.0</td>\n",
       "      <td>85</td>\n",
       "      <td>77.88</td>\n",
       "      <td>75.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date store_id product_id  inventory_level  price  discount  \\\n",
       "0 2022-01-02     S001      P0001              116  27.95        10   \n",
       "1 2022-01-03     S001      P0001              154  62.70        20   \n",
       "2 2022-01-04     S001      P0001               85  77.88        15   \n",
       "\n",
       "   competitor_price  units_ordered  demand_forecast  holiday_promo  ...  \\\n",
       "0             30.89            104            92.94              0  ...   \n",
       "1             58.22            189             5.36              0  ...   \n",
       "2             75.99            193            52.87              1  ...   \n",
       "\n",
       "   units_ordered_low_iqr units_ordered_high_iqr units_sold_outlier_flag  \\\n",
       "0                  -67.0                  285.0                       0   \n",
       "1                  -67.0                  285.0                       0   \n",
       "2                  -67.0                  285.0                       0   \n",
       "\n",
       "   units_sold_w  units_sold_low_iqr  units_sold_high_iqr  units_sold_imputed  \\\n",
       "0         219.0            -359.625              599.375               219.0   \n",
       "1         151.0            -359.625              599.375               151.0   \n",
       "2         262.0            -359.625              599.375               262.0   \n",
       "\n",
       "   inventory_level_imputed  price_imputed  competitor_price_imputed  \n",
       "0                      116          27.95                     30.89  \n",
       "1                      154          62.70                     58.22  \n",
       "2                       85          77.88                     75.99  \n",
       "\n",
       "[3 rows x 47 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) pick the most processed dataframe available\n",
    "for cand in [\"df_imp\", \"dfq\", \"df\"]:\n",
    "    if cand in globals():\n",
    "        base_df = globals()[cand].copy()\n",
    "        print(f\"Using dataframe: {cand}\")\n",
    "        break\n",
    "assert base_df is not None, \"No dataframe found (df_imp/dfq/df).\"\n",
    "\n",
    "# 2) ensure datetime + keys as string\n",
    "base_df[\"date\"] = pd.to_datetime(base_df[\"date\"], errors=\"coerce\")\n",
    "assert base_df[\"date\"].notna().any(), \"No valid dates.\"\n",
    "\n",
    "for k in [\"store_id\", \"product_id\"]:\n",
    "    if k in base_df.columns:\n",
    "        base_df[k] = base_df[k].astype(\"string\")\n",
    "    else:\n",
    "        raise ValueError(f\"Missing key column: {k}\")\n",
    "    \n",
    "# 3) choose target (prefer *_imputed)\n",
    "CANDIDATE_TARGETS = [\"inventory_level_imputed\",\"units_sold_imputed\",\"units_sold\",\"units_sold_est\",\"inventory_level\"]\n",
    "TARGET_COL = next((c for c in CANDIDATE_TARGETS if c in base_df.columns), None)\n",
    "if TARGET_COL is None:\n",
    "    raise ValueError(\"No suitable target column found. Add one of: \" + \", \".join(CANDIDATE_TARGETS))\n",
    "print(\"TARGET_COL =\", TARGET_COL)\n",
    "\n",
    "# 4) sort\n",
    "base_df = base_df.sort_values([\"store_id\",\"product_id\",\"date\"]).reset_index(drop=True)\n",
    "base_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6bd5ad",
   "metadata": {},
   "source": [
    "# Cell 2 â€” define covariates (dynamic + static) with graceful fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "172ced21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic covariates (normalized): ['price_feature', 'competitor_price_feature', 'discount', 'holiday_promo', 'seasonality', 'demand_forecast', 'units_ordered']\n",
      "Static covariates: ['category', 'region']\n"
     ]
    }
   ],
   "source": [
    "# dynamic-known candidates (will keep only those existing)\n",
    "dyn_cov_candidates = [\n",
    "    \"price_imputed\",\"price\",\n",
    "    \"competitor_price_imputed\",\"competitor_price\",\n",
    "    \"discount\",\n",
    "    \"is_holiday_promo\",\"holiday_promo\",\n",
    "    \"seasonality\",\n",
    "    \"demand_forecast\",\n",
    "    \"units_ordered\",\n",
    "    # winsorized versions (optional)\n",
    "    \"price_w\",\"inventory_level_w\"\n",
    "]\n",
    "DYN_COVS = [c for c in dyn_cov_candidates if c in base_df.columns]\n",
    "\n",
    "# prefer the _imputed versions by aliasing\n",
    "def alias_pref(df, preferred, fallback, new_name):\n",
    "    if preferred in df.columns:\n",
    "        df[new_name] = df[preferred]\n",
    "        return new_name\n",
    "    if fallback in df.columns:\n",
    "        df[new_name] = df[fallback]\n",
    "        return new_name\n",
    "    return None\n",
    "\n",
    "# normalize common covariates to unified names\n",
    "norm_covs = []\n",
    "if alias_pref(base_df, \"price_imputed\",\"price\",\"price_feature\"):          \n",
    "    norm_covs.append(\"price_feature\")\n",
    "if alias_pref(base_df, \"competitor_price_imputed\",\"competitor_price\",\"competitor_price_feature\"): \n",
    "    norm_covs.append(\"competitor_price_feature\")\n",
    "if \"discount\" in base_df.columns:\n",
    "    norm_covs.append(\"discount\")\n",
    "if \"is_holiday_promo\" in base_df.columns:\n",
    "    norm_covs.append(\"is_holiday_promo\")\n",
    "elif \"holiday_promo\" in base_df.columns:\n",
    "    norm_covs.append(\"holiday_promo\")\n",
    "if \"seasonality\" in base_df.columns:     \n",
    "    norm_covs.append(\"seasonality\")\n",
    "if \"demand_forecast\" in base_df.columns:  \n",
    "    norm_covs.append(\"demand_forecast\")\n",
    "if \"units_ordered\" in base_df.columns:   \n",
    "    norm_covs.append(\"units_ordered\")\n",
    "\n",
    "# static covariates (optional)\n",
    "STATIC_COVS = [c for c in [\"category\",\"region\"] if c in base_df.columns]\n",
    "\n",
    "print(\"Dynamic covariates (normalized):\", norm_covs)\n",
    "print(\"Static covariates:\", STATIC_COVS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f366626b",
   "metadata": {},
   "source": [
    "# Cell 3 â€” enforce daily continuity (fill date gaps per series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc1d0bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily continuity enforced. Shape: (73000, 49)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Taha\\AppData\\Local\\Temp\\ipykernel_15532\\2008631175.py:12: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_daily = base_df.groupby([\"store_id\",\"product_id\"], group_keys=False).apply(ensure_daily_continuity).reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "store_id",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "product_id",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "inventory_level",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "price",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "discount",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "competitor_price",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "units_ordered",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "demand_forecast",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "holiday_promo",
         "rawType": "int8",
         "type": "integer"
        },
        {
         "name": "weather",
         "rawType": "int8",
         "type": "integer"
        },
        {
         "name": "category",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "region",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "seasonality",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "prev_inventory",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "units_sold_est",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "units_sold",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "units_sold_imputed_from_balance",
         "rawType": "int8",
         "type": "integer"
        },
        {
         "name": "inventory_level_isna",
         "rawType": "int8",
         "type": "integer"
        },
        {
         "name": "price_isna",
         "rawType": "int8",
         "type": "integer"
        },
        {
         "name": "competitor_price_isna",
         "rawType": "int8",
         "type": "integer"
        },
        {
         "name": "units_ordered_isna",
         "rawType": "int8",
         "type": "integer"
        },
        {
         "name": "units_sold_isna",
         "rawType": "int8",
         "type": "integer"
        },
        {
         "name": "inventory_level_outlier_flag",
         "rawType": "int8",
         "type": "integer"
        },
        {
         "name": "inventory_level_w",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "inventory_level_low_iqr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "inventory_level_high_iqr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "price_outlier_flag",
         "rawType": "int8",
         "type": "integer"
        },
        {
         "name": "price_w",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "price_low_iqr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "price_high_iqr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "competitor_price_outlier_flag",
         "rawType": "int8",
         "type": "integer"
        },
        {
         "name": "competitor_price_w",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "competitor_price_low_iqr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "competitor_price_high_iqr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "units_ordered_outlier_flag",
         "rawType": "int8",
         "type": "integer"
        },
        {
         "name": "units_ordered_w",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "units_ordered_low_iqr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "units_ordered_high_iqr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "units_sold_outlier_flag",
         "rawType": "int8",
         "type": "integer"
        },
        {
         "name": "units_sold_w",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "units_sold_low_iqr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "units_sold_high_iqr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "units_sold_imputed",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "inventory_level_imputed",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "price_imputed",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "competitor_price_imputed",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "price_feature",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "competitor_price_feature",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "dfa7c1d3-f100-4a31-a07c-83ede40934a1",
       "rows": [
        [
         "0",
         "2022-01-02 00:00:00",
         "S001",
         "P0001",
         "116",
         "27.95",
         "10",
         "30.89",
         "104",
         "92.94",
         "0",
         "1",
         "Groceries",
         "West",
         null,
         "231.0",
         "219.0",
         "219.0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "116",
         "-182.625",
         "730.375",
         "0",
         "27.95",
         "-31.241249999999972",
         "142.40874999999997",
         "0",
         "30.89",
         "-33.01374999999998",
         "143.37624999999997",
         "0",
         "104",
         "-67.0",
         "285.0",
         "0",
         "219.0",
         "-359.625",
         "599.375",
         "219.0",
         "116",
         "27.95",
         "30.89",
         "27.95",
         "30.89"
        ],
        [
         "1",
         "2022-01-03 00:00:00",
         "S001",
         "P0001",
         "154",
         "62.7",
         "20",
         "58.22",
         "189",
         "5.36",
         "0",
         "2",
         "Electronics",
         "West",
         null,
         "116.0",
         "151.0",
         "151.0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "154",
         "-182.625",
         "730.375",
         "0",
         "62.7",
         "-31.241249999999972",
         "142.40874999999997",
         "0",
         "58.22",
         "-33.01374999999998",
         "143.37624999999997",
         "0",
         "189",
         "-67.0",
         "285.0",
         "0",
         "151.0",
         "-359.625",
         "599.375",
         "151.0",
         "154",
         "62.7",
         "58.22",
         "62.7",
         "58.22"
        ],
        [
         "2",
         "2022-01-04 00:00:00",
         "S001",
         "P0001",
         "85",
         "77.88",
         "15",
         "75.99",
         "193",
         "52.87",
         "1",
         "1",
         "Groceries",
         "South",
         null,
         "154.0",
         "262.0",
         "262.0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "85",
         "-182.625",
         "730.375",
         "0",
         "77.88",
         "-31.241249999999972",
         "142.40874999999997",
         "0",
         "75.99",
         "-33.01374999999998",
         "143.37624999999997",
         "0",
         "193",
         "-67.0",
         "285.0",
         "0",
         "262.0",
         "-359.625",
         "599.375",
         "262.0",
         "85",
         "77.88",
         "75.99",
         "77.88",
         "75.99"
        ]
       ],
       "shape": {
        "columns": 49,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>inventory_level</th>\n",
       "      <th>price</th>\n",
       "      <th>discount</th>\n",
       "      <th>competitor_price</th>\n",
       "      <th>units_ordered</th>\n",
       "      <th>demand_forecast</th>\n",
       "      <th>holiday_promo</th>\n",
       "      <th>...</th>\n",
       "      <th>units_sold_outlier_flag</th>\n",
       "      <th>units_sold_w</th>\n",
       "      <th>units_sold_low_iqr</th>\n",
       "      <th>units_sold_high_iqr</th>\n",
       "      <th>units_sold_imputed</th>\n",
       "      <th>inventory_level_imputed</th>\n",
       "      <th>price_imputed</th>\n",
       "      <th>competitor_price_imputed</th>\n",
       "      <th>price_feature</th>\n",
       "      <th>competitor_price_feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>S001</td>\n",
       "      <td>P0001</td>\n",
       "      <td>116</td>\n",
       "      <td>27.95</td>\n",
       "      <td>10</td>\n",
       "      <td>30.89</td>\n",
       "      <td>104</td>\n",
       "      <td>92.94</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>-359.625</td>\n",
       "      <td>599.375</td>\n",
       "      <td>219.0</td>\n",
       "      <td>116</td>\n",
       "      <td>27.95</td>\n",
       "      <td>30.89</td>\n",
       "      <td>27.95</td>\n",
       "      <td>30.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>S001</td>\n",
       "      <td>P0001</td>\n",
       "      <td>154</td>\n",
       "      <td>62.70</td>\n",
       "      <td>20</td>\n",
       "      <td>58.22</td>\n",
       "      <td>189</td>\n",
       "      <td>5.36</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>-359.625</td>\n",
       "      <td>599.375</td>\n",
       "      <td>151.0</td>\n",
       "      <td>154</td>\n",
       "      <td>62.70</td>\n",
       "      <td>58.22</td>\n",
       "      <td>62.70</td>\n",
       "      <td>58.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>S001</td>\n",
       "      <td>P0001</td>\n",
       "      <td>85</td>\n",
       "      <td>77.88</td>\n",
       "      <td>15</td>\n",
       "      <td>75.99</td>\n",
       "      <td>193</td>\n",
       "      <td>52.87</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>-359.625</td>\n",
       "      <td>599.375</td>\n",
       "      <td>262.0</td>\n",
       "      <td>85</td>\n",
       "      <td>77.88</td>\n",
       "      <td>75.99</td>\n",
       "      <td>77.88</td>\n",
       "      <td>75.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date store_id product_id  inventory_level  price  discount  \\\n",
       "0 2022-01-02     S001      P0001              116  27.95        10   \n",
       "1 2022-01-03     S001      P0001              154  62.70        20   \n",
       "2 2022-01-04     S001      P0001               85  77.88        15   \n",
       "\n",
       "   competitor_price  units_ordered  demand_forecast  holiday_promo  ...  \\\n",
       "0             30.89            104            92.94              0  ...   \n",
       "1             58.22            189             5.36              0  ...   \n",
       "2             75.99            193            52.87              1  ...   \n",
       "\n",
       "   units_sold_outlier_flag units_sold_w units_sold_low_iqr  \\\n",
       "0                        0        219.0           -359.625   \n",
       "1                        0        151.0           -359.625   \n",
       "2                        0        262.0           -359.625   \n",
       "\n",
       "   units_sold_high_iqr  units_sold_imputed  inventory_level_imputed  \\\n",
       "0              599.375               219.0                      116   \n",
       "1              599.375               151.0                      154   \n",
       "2              599.375               262.0                       85   \n",
       "\n",
       "   price_imputed  competitor_price_imputed  price_feature  \\\n",
       "0          27.95                     30.89          27.95   \n",
       "1          62.70                     58.22          62.70   \n",
       "2          77.88                     75.99          77.88   \n",
       "\n",
       "   competitor_price_feature  \n",
       "0                     30.89  \n",
       "1                     58.22  \n",
       "2                     75.99  \n",
       "\n",
       "[3 rows x 49 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ensure_daily_continuity(g: pd.DataFrame) -> pd.DataFrame:\n",
    "    g = g.sort_values(\"date\")\n",
    "    full_idx = pd.date_range(g[\"date\"].min(), g[\"date\"].max(), freq=\"D\")\n",
    "    g = g.set_index(\"date\").reindex(full_idx).rename_axis(\"date\").reset_index()\n",
    "    # fill keys/statics\n",
    "    for k in [\"store_id\",\"product_id\"]:\n",
    "        g[k] = g[k].ffill().bfill()\n",
    "    for c in STATIC_COVS:\n",
    "        g[c] = g[c].ffill().bfill()\n",
    "    return g\n",
    "\n",
    "df_daily = base_df.groupby([\"store_id\",\"product_id\"], group_keys=False).apply(ensure_daily_continuity).reset_index(drop=True)\n",
    "\n",
    "# fill covariates softly (only covs, NOT the target)\n",
    "df_daily = df_daily.sort_values([\"store_id\",\"product_id\",\"date\"]).reset_index(drop=True)\n",
    "for c in norm_covs:\n",
    "    df_daily[c] = (\n",
    "        df_daily\n",
    "        .groupby([\"store_id\",\"product_id\"])[c]\n",
    "        .transform(lambda s: s.ffill().bfill())\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"Daily continuity enforced. Shape:\", df_daily.shape)\n",
    "df_daily.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71008a2b",
   "metadata": {},
   "source": [
    "# Cell 4 â€” build series_id and long-format (date, series_id, target, covariatesâ€¦)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ae50463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model columns: ['date', 'series_id', 'target', 'price_feature', 'competitor_price_feature', 'discount', 'holiday_promo', 'seasonality', 'demand_forecast', 'units_ordered']\n",
      "Series: 100 | Date range: 2022-01-02 00:00:00 â†’ 2024-01-01 00:00:00\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "series_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "target",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "price_feature",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "competitor_price_feature",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "discount",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "holiday_promo",
         "rawType": "int8",
         "type": "integer"
        },
        {
         "name": "seasonality",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "demand_forecast",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "units_ordered",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "dfedfa29-e425-44a7-852d-bcefd514b4f2",
       "rows": [
        [
         "0",
         "2022-01-02 00:00:00",
         "S001_P0001",
         "116",
         "27.95",
         "30.89",
         "10",
         "0",
         null,
         "92.94",
         "104"
        ],
        [
         "1",
         "2022-01-03 00:00:00",
         "S001_P0001",
         "154",
         "62.7",
         "58.22",
         "20",
         "0",
         null,
         "5.36",
         "189"
        ],
        [
         "2",
         "2022-01-04 00:00:00",
         "S001_P0001",
         "85",
         "77.88",
         "75.99",
         "15",
         "1",
         null,
         "52.87",
         "193"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>series_id</th>\n",
       "      <th>target</th>\n",
       "      <th>price_feature</th>\n",
       "      <th>competitor_price_feature</th>\n",
       "      <th>discount</th>\n",
       "      <th>holiday_promo</th>\n",
       "      <th>seasonality</th>\n",
       "      <th>demand_forecast</th>\n",
       "      <th>units_ordered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>S001_P0001</td>\n",
       "      <td>116</td>\n",
       "      <td>27.95</td>\n",
       "      <td>30.89</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92.94</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>S001_P0001</td>\n",
       "      <td>154</td>\n",
       "      <td>62.70</td>\n",
       "      <td>58.22</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.36</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>S001_P0001</td>\n",
       "      <td>85</td>\n",
       "      <td>77.88</td>\n",
       "      <td>75.99</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.87</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date   series_id  target  price_feature  competitor_price_feature  \\\n",
       "0 2022-01-02  S001_P0001     116          27.95                     30.89   \n",
       "1 2022-01-03  S001_P0001     154          62.70                     58.22   \n",
       "2 2022-01-04  S001_P0001      85          77.88                     75.99   \n",
       "\n",
       "   discount  holiday_promo  seasonality  demand_forecast  units_ordered  \n",
       "0        10              0          NaN            92.94            104  \n",
       "1        20              0          NaN             5.36            189  \n",
       "2        15              1          NaN            52.87            193  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ready = df_daily.copy()\n",
    "df_ready[\"series_id\"] = df_ready[\"store_id\"].astype(str) + \"_\" + df_ready[\"product_id\"].astype(str)\n",
    "\n",
    "cols_model = [\"date\",\"series_id\", TARGET_COL] + norm_covs\n",
    "df_ready = df_ready[cols_model].rename(columns={TARGET_COL: \"target\"})\n",
    "print(\"Model columns:\", df_ready.columns.tolist())\n",
    "print(\"Series:\", df_ready[\"series_id\"].nunique(), \"| Date range:\", df_ready[\"date\"].min(), \"â†’\", df_ready[\"date\"].max())\n",
    "df_ready.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae829c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date\n",
      "series_id\n",
      "target\n",
      "price_feature\n",
      "competitor_price_feature\n",
      "discount\n",
      "holiday_promo\n",
      "demand_forecast\n",
      "units_ordered\n",
      "target_raw\n"
     ]
    }
   ],
   "source": [
    "CONTEXT = 512 # input sequence length. it means how many past days to look at\n",
    "HORIZON = 7 # forecast horizon. it means how many future days to predict\n",
    "N_FOLDS = 4 # number of folds for cross-validation\n",
    "\n",
    "df = df_ready.copy()\n",
    "# Remove 'inplace=True' and rely on the assignment\n",
    "df = df.drop(columns=['seasonality']) # because it has too many missing values and is not very useful for forecasting we drop it\n",
    "\n",
    "panel = df.copy()\n",
    "panel[\"target_raw\"] = panel[\"target\"]\n",
    "for col in panel.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd0ed451",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1e-8\n",
    "\n",
    "def _align_torch(y, yhat, strict=False):\n",
    "    if not torch.is_tensor(y):    y = torch.tensor(y, dtype=torch.float32)\n",
    "    if not torch.is_tensor(yhat): yhat = torch.tensor(yhat, dtype=torch.float32)\n",
    "    if y.shape != yhat.shape:\n",
    "        m = min(y.shape[0], yhat.shape[0])\n",
    "        if strict:\n",
    "            raise ValueError(f\"Shape mismatch y={y.shape} yhat={yhat.shape}\")\n",
    "        y, yhat = y[:m], yhat[:m]\n",
    "    return y, yhat\n",
    "\n",
    "def mae(y, yhat, strict=False):\n",
    "    y, yhat = _align_torch(y, yhat, strict)\n",
    "    return torch.mean(torch.abs(y - yhat))\n",
    "\n",
    "def rmse(y, yhat, strict=False):\n",
    "    y, yhat = _align_torch(y, yhat, strict)\n",
    "    return torch.sqrt(torch.mean((y - yhat) ** 2))\n",
    "\n",
    "def smape(y, yhat, strict=False, eps=EPS):\n",
    "    y, yhat = _align_torch(y, yhat, strict)\n",
    "    return 200.0 * torch.mean(torch.abs(y - yhat) / (torch.abs(y) + torch.abs(yhat) + eps))\n",
    "\n",
    "def wape(y, yhat, strict=False, eps=EPS):\n",
    "    y, yhat = _align_torch(y, yhat, strict)\n",
    "    return 100.0 * torch.sum(torch.abs(y - yhat)) / (torch.sum(torch.abs(y)) + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "785063d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Timestamp('2023-12-04 00:00:00'),\n",
       " Timestamp('2023-12-11 00:00:00'),\n",
       " Timestamp('2023-12-18 00:00:00'),\n",
       " Timestamp('2023-12-25 00:00:00')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dates = np.sort(panel[\"date\"].unique())\n",
    "assert len(all_dates) > (N_FOLDS + 1) * HORIZON\n",
    "\n",
    "fold_cutoffs = []\n",
    "for k in range(N_FOLDS):\n",
    "    train_end_idx = len(all_dates) - (N_FOLDS - k) * HORIZON\n",
    "    cutoff = all_dates[train_end_idx - 1]   \n",
    "    fold_cutoffs.append(pd.Timestamp(cutoff))\n",
    "\n",
    "fold_cutoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2ad27ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cutoff is the last date of the training period\n",
    "# context is how many past days to look at\n",
    "#horizon is how many future days to predict\n",
    "def get_hist_and_truth(sdf, cutoff, context=CONTEXT, horizon=HORIZON):\n",
    "    sdf = sdf.sort_values(\"date\")\n",
    "    train_mask = sdf[\"date\"] <= cutoff\n",
    "    #pd.TimeDelta means a duration, the difference between two dates or times.\n",
    "    # For example, pd.Timedelta(days=5) represents a duration of 5 days.\n",
    "    val_mask = (sdf[\"date\"]>= cutoff) & (sdf[\"date\"] <= cutoff + pd.Timedelta(days=horizon))\n",
    "\n",
    "    train_df = sdf.loc[train_mask] # .loc means to access a group of rows and columns by labels or a boolean array\n",
    "    val_df = sdf.loc[val_mask]\n",
    "\n",
    "    if len(val_df) < horizon or len(train_df) == 0:\n",
    "        return [], [], False\n",
    "    \n",
    "    y_hist = train_df[\"target\"].astype(float).values[-context:].tolist()\n",
    "\n",
    "    y_true = val_df[\"target_raw\"].astype(float).values\n",
    "    if np.isnan(y_true).any():\n",
    "        return [], [], False\n",
    "\n",
    "    return y_hist, y_true.tolist(), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cda92ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean7_forecast(history, horizon=HORIZON):\n",
    "    if not history:\n",
    "        return np.zeros(horizon)\n",
    "    k = min(7, len(history))\n",
    "    return np.full(horizon, float(np.mean(history[-k:])))\n",
    "\n",
    "try:\n",
    "    TFM = timesfm.TimesFM_2p5_200M_torch.from_pretrained(\"google/timesfm-2.5-200m-pytorch\")\n",
    "    TFM.compile(ForecastConfig(max_context=CONTEXT, max_horizon=HORIZON))\n",
    "    TFM_OK = True\n",
    "except Exception as e:\n",
    "    print(\"[Warn] TimesFM unavailable â†’ fallback to baseline only.\", e)\n",
    "    TFM = None\n",
    "    TFM_OK = False\n",
    "\n",
    "def forecast_batch(hist_list, horizon=HORIZON, batch=64, use_timesfm=True):\n",
    "    preds = []\n",
    "    if use_timesfm and TFM_OK:\n",
    "        for i in range(0, len(hist_list), batch):\n",
    "            chunk = hist_list[i:i+batch]\n",
    "            pf, _ = TFM.forecast(horizon=horizon, inputs=[list(map(float, seq)) for seq in chunk])\n",
    "            preds.extend([np.asarray(x, float) for x in pf])\n",
    "        return preds\n",
    "    # fallback: baseline\n",
    "    return [mean7_forecast(seq, horizon=horizon) for seq in hist_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "32d05327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold 1] series=100 | sMAPE(TimesFM): 46.02\n",
      "[fold 2] series=100 | sMAPE(TimesFM): 44.82\n",
      "[fold 3] series=100 | sMAPE(TimesFM): 45.28\n",
      "[fold 4] series=100 | sMAPE(TimesFM): 44.64\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "fold",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sMAPE",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "MAE",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "RMSE",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "sMAPE_baseline",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "MAE_baseline",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "RMSE_baseline",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "994cd810-c5bb-45fa-a32e-12c1337f0d43",
       "rows": [
        [
         "1",
         "46.02423828125",
         "112.636337890625",
         "128.663046875",
         "46.6904736328125",
         "114.941240234375",
         "133.64037109375"
        ],
        [
         "2",
         "44.824921875",
         "114.002109375",
         "128.99537109375",
         "46.732314453125",
         "118.197353515625",
         "136.004052734375"
        ],
        [
         "3",
         "45.27833984375",
         "113.683564453125",
         "129.84201171875",
         "46.5991162109375",
         "117.980224609375",
         "135.17150390625"
        ],
        [
         "4",
         "44.644345703125",
         "110.18876953125",
         "125.989873046875",
         "46.233505859375",
         "115.139365234375",
         "134.37412109375"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sMAPE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>sMAPE_baseline</th>\n",
       "      <th>MAE_baseline</th>\n",
       "      <th>RMSE_baseline</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46.024238</td>\n",
       "      <td>112.636338</td>\n",
       "      <td>128.663047</td>\n",
       "      <td>46.690474</td>\n",
       "      <td>114.94124</td>\n",
       "      <td>133.640371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.824922</td>\n",
       "      <td>114.002109</td>\n",
       "      <td>128.995371</td>\n",
       "      <td>46.732314</td>\n",
       "      <td>118.197354</td>\n",
       "      <td>136.004053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45.27834</td>\n",
       "      <td>113.683564</td>\n",
       "      <td>129.842012</td>\n",
       "      <td>46.599116</td>\n",
       "      <td>117.980225</td>\n",
       "      <td>135.171504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44.644346</td>\n",
       "      <td>110.18877</td>\n",
       "      <td>125.989873</td>\n",
       "      <td>46.233506</td>\n",
       "      <td>115.139365</td>\n",
       "      <td>134.374121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sMAPE         MAE        RMSE sMAPE_baseline MAE_baseline  \\\n",
       "fold                                                                  \n",
       "1     46.024238  112.636338  128.663047      46.690474    114.94124   \n",
       "2     44.824922  114.002109  128.995371      46.732314   118.197354   \n",
       "3      45.27834  113.683564  129.842012      46.599116   117.980225   \n",
       "4     44.644346   110.18877  125.989873      46.233506   115.139365   \n",
       "\n",
       "     RMSE_baseline  \n",
       "fold                \n",
       "1       133.640371  \n",
       "2       136.004053  \n",
       "3       135.171504  \n",
       "4       134.374121  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run_backtest(panel, cutoffs, use_timesfm=True):\n",
    "    rows = []\n",
    "    for fold_idx, cutoff in enumerate(cutoffs, 1):\n",
    "        sids, Hlist, Ytrue = [], [], []\n",
    "        for sid, sdf in panel.groupby(\"series_id\"):\n",
    "            y_hist, y_true, ok = get_hist_and_truth(sdf, cutoff)\n",
    "            if not ok or len(y_hist)==0:\n",
    "                continue\n",
    "            sids.append(sid); Hlist.append(y_hist); Ytrue.append(np.asarray(y_true, float))\n",
    "\n",
    "        if not sids:\n",
    "            print(f\"[fold {fold_idx}] no evaluable series; skip.\")\n",
    "            continue\n",
    "\n",
    "        # TimesFM ÛŒØ§ fallback\n",
    "        Yhat_main = forecast_batch(Hlist, horizon=HORIZON, use_timesfm=use_timesfm)\n",
    "        # baseline Ø¨Ø±Ø§ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡\n",
    "        Yhat_base = [mean7_forecast(h) for h in Hlist]\n",
    "\n",
    "        # Ø°Ø®ÛŒØ±Ù‡ Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§\n",
    "        for sid, y, yhat_m, yhat_b in zip(sids, Ytrue, Yhat_main, Yhat_base):\n",
    "            rows.append({\n",
    "                \"fold\": fold_idx,\n",
    "                \"cutoff\": cutoff,\n",
    "                \"series_id\": sid,\n",
    "                \"model\": \"TimesFM\" if (use_timesfm and TFM_OK) else \"Mean7\",\n",
    "                \"sMAPE\": smape(y, yhat_m),\n",
    "                \"MAE\":   mae(y, yhat_m),\n",
    "                \"RMSE\":  rmse(y, yhat_m),\n",
    "                \"sMAPE_baseline\": smape(y, yhat_b),\n",
    "                \"MAE_baseline\":   mae(y, yhat_b),\n",
    "                \"RMSE_baseline\":  rmse(y, yhat_b),\n",
    "            })\n",
    "\n",
    "        fold_mean = np.mean([r[\"sMAPE\"] for r in rows if r[\"fold\"]==fold_idx])\n",
    "        print(f\"[fold {fold_idx}] series={len(sids)} | sMAPE({('TimesFM' if (use_timesfm and TFM_OK) else 'Mean7')}): {fold_mean:.2f}\")\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "metrics_df = run_backtest(panel, fold_cutoffs, use_timesfm=True)\n",
    "metrics_df.to_csv(\"backtest_metrics.csv\", index=False)\n",
    "metrics_df.groupby(\"fold\")[[\"sMAPE\",\"MAE\",\"RMSE\",\"sMAPE_baseline\",\"MAE_baseline\",\"RMSE_baseline\"]].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
